{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<CENTER style=\"font-size:40px;\">Experiment 4</CENTER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;width:100%}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:16px;\n",
    "  overflow:hidden;padding:10px 10px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:16px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 10px;word-break:normal;}\n",
    ".tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top;}\n",
    ".col1 { width: 20%;}\n",
    ".col2 { width: 80%;}\n",
    "</style>\n",
    "<table style=\"width: 100%;\">\n",
    "  <tr>\n",
    "    <td>Name</td>\n",
    "    <td>Pranay Singhvi</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>UID</td>\n",
    "    <td>2021300126</td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIM: Perform document classification using NB(no use of library of NB classifier)\n",
    "\n",
    "Copy abstract of papers and create labelled dataset.\n",
    "\n",
    "Create word count vectors. Each row represents a document, and each column represents a word.\n",
    "\n",
    "Read text from set of test documents and classify the unlabelled documents.\n",
    "\n",
    "Generate confusion matrix, and calculate accuracy, precision, recall, F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes is a probabilistic algorithm based on Bayes' theorem, which calculates the probability of a hypothesis given observed evidence. In the context of text classification, Naive Bayes is often used to categorize documents into predefined classes or categories based on their content.\n",
    "\n",
    "Here is a simplified explanation of the Naive Bayes text classification algorithm:\n",
    "\n",
    "1. **Bayes' Theorem:**\n",
    "   Bayes' theorem is the foundation of Naive Bayes. It states:\n",
    "$$\n",
    "    P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)} \n",
    "$$\n",
    "   In the context of text classification:\n",
    "   -  P(A|B)  is the probability of document belonging to class A given the observed words in the document.\n",
    "   -  P(B|A)  is the probability of observing the words in the document given that the document belongs to class A.\n",
    "   -  P(A)  is the prior probability of a document belonging to class A.\n",
    "   -  P(B)  is the probability of observing the words in the document (regardless of class).\n",
    "2. **Naive Assumption:**\n",
    "   The \"naive\" assumption in Naive Bayes is that the features (words in the case of text classification) are conditionally independent given the class label. This means that the presence or absence of a particular word does not affect the presence or absence of any other word. Although this assumption simplifies the model, it may not hold true in reality.\n",
    "\n",
    "3. **Text Classification:**\n",
    "   In text classification, a document is represented as a bag-of-words, which disregards the order of words and focuses only on their frequency. Each word becomes a feature, and the model calculates the probability of a document belonging to each class based on the presence or absence of these words.\n",
    "\n",
    "   The probability of a document D belonging to class C is calculated as:\n",
    "   $$\n",
    "    P(C|D) \\propto P(C) \\cdot \\prod_{i=1}^{n} P(w_i|C) \n",
    "$$\n",
    "   - P(C): Prior probability of class C.\n",
    "   -  P(w_i|C) : Probability of word w_i occurring in documents of class C.\n",
    "\n",
    "4. **Smoothing:**\n",
    "   To handle the issue of zero probabilities when a word is not present in the training data for a particular class, smoothing techniques like Laplace smoothing or add-one smoothing are often employed.\n",
    "\n",
    "5. **Classification Decision:**\n",
    "   The class with the highest posterior probability is assigned as the predicted class for the document.\n",
    "\n",
    "Naive Bayes is computationally efficient, especially with large datasets, and it often performs well in text classification tasks, despite its simplifying assumptions. It's widely used in spam filtering, sentiment analysis, and document categorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fc/b_3ntmtx3kv_43ckpdzjd47r0000gn/T/ipykernel_46145/2485052407.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('df_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\w'\n",
      "/var/folders/fc/b_3ntmtx3kv_43ckpdzjd47r0000gn/T/ipykernel_46145/2711725740.py:2: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  data['Text'] = data['Text'].str.replace('[^\\w\\s]', '').str.lower()\n"
     ]
    }
   ],
   "source": [
    "# Remove punctuation and convert text to lowercase\n",
    "data['Text'] = data['Text'].str.replace('[^\\w\\s]', '').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Implement Naive Bayes classifier\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.class_word_counts = defaultdict(lambda: defaultdict(int))\n",
    "        self.class_counts = defaultdict(int)\n",
    "        self.vocab = set()\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        for i in range(len(X)):\n",
    "            text = X.iloc[i]\n",
    "            label = y.iloc[i]\n",
    "            self.class_counts[label] += 1\n",
    "            words = text.split()\n",
    "            for word in words:\n",
    "                self.class_word_counts[label][word] += 1\n",
    "                self.vocab.add(word)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        probabilities = []\n",
    "        for i in range(len(X)):\n",
    "            text = X.iloc[i]\n",
    "            max_score = float('-inf')\n",
    "            best_class = None\n",
    "            words = text.split()\n",
    "            class_probs = {}\n",
    "            for label in self.class_counts.keys():\n",
    "                score = np.log(self.class_counts[label] / sum(self.class_counts.values()))\n",
    "                for word in words:\n",
    "                    count = self.class_word_counts[label][word] + 1\n",
    "                    total_count = len(self.vocab) + sum(self.class_word_counts[label].values())\n",
    "                    score += np.log(count / total_count)\n",
    "                class_probs[label] = score\n",
    "                if score > max_score:\n",
    "                    max_score = score\n",
    "                    best_class = label\n",
    "            predictions.append(best_class)\n",
    "            probabilities.append(class_probs)\n",
    "        return predictions, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = NaiveBayesClassifier()\n",
    "classifier.train(train_data['Text'], train_data['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, probabilities = classifier.predict(test_data['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.85 %\n",
      "Precision: 96.75 %\n",
      "Recall: 96.81 %\n",
      "F1 Score: 96.76 %\n",
      "Confusion Matrix:\n",
      "[[90  0  1  0  1]\n",
      " [ 1 97  0  0  0]\n",
      " [ 0  0 75  2  0]\n",
      " [ 2  1  1 72  0]\n",
      " [ 2  0  3  0 97]]\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(test_data['Label'], predictions)\n",
    "precision = precision_score(test_data['Label'], predictions, average='macro')\n",
    "recall = recall_score(test_data['Label'], predictions, average='macro')\n",
    "f1 = f1_score(test_data['Label'], predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(test_data['Label'], predictions)\n",
    "\n",
    "formatted_accuracy = \"{:.2f}\".format(accuracy*100)\n",
    "formatted_precision = \"{:.2f}\".format(precision*100)\n",
    "formatted_recall = \"{:.2f}\".format(recall*100)\n",
    "formatted_f1 = \"{:.2f}\".format(f1*100)\n",
    "print(f\"Accuracy: {formatted_accuracy} %\")\n",
    "\n",
    "print(f\"Precision: {formatted_precision} %\")\n",
    "print(f\"Recall: {formatted_recall} %\")\n",
    "print(f\"F1 Score: {formatted_f1} %\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "I like to invest in stock market\n",
      "Probabilities:\n",
      "Entertainment: 3.277826610006645e-25\n",
      "Business: 2.62501793062563e-22\n",
      "Sport: 3.2523863576518463e-25\n",
      "Politics: 1.3185633709796263e-24\n",
      "Technology: 5.528931566700224e-24\n",
      "Predicted Class: Business\n"
     ]
    }
   ],
   "source": [
    "def predict_single(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    prediction, probability = classifier.predict(pd.Series([sentence]))\n",
    "    print(\"Probabilities:\")\n",
    "    category_mapping = {0: \"Politics\", 1: \"Sport\", 2: \"Technology\", 3: \"Entertainment\", 4: \"Business\", 5: \"None\"}\n",
    "    for label, prob in probability[0].items():\n",
    "        print(f\"{category_mapping[label]}: {np.exp(prob)}\")\n",
    "    print(\"Predicted Class:\", category_mapping[prediction[0]])\n",
    "\n",
    "# Cell 10: Test prediction on a single input sentence\n",
    "input_sentence = input(\"Enter a sentence: \")\n",
    "print(\"Predicting...\")\n",
    "print(input_sentence)\n",
    "predict_single(input_sentence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Curiosity questions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What is the relation between accuracy and precision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy and precision are two different metrics used to evaluate the performance of classification models, and they are related in the context of evaluating the correctness of predictions.\n",
    "\n",
    "1. **Accuracy:**\n",
    "   - Accuracy is a measure of the overall correctness of the model's predictions.\n",
    "   - It is calculated as the ratio of correctly predicted instances to the total instances.\n",
    "   - Formula:$$ \\text{Accuracy} = \\frac{\\text{True Positives} + \\text{True Negatives}}{\\text{Total Instances}}  $$\n",
    "\n",
    "2. **Precision:**\n",
    "   - Precision focuses on the accuracy of the positive predictions made by the model.\n",
    "   - It is calculated as the ratio of correctly predicted positive instances to the total predicted positive instances.\n",
    "   - Formula: $$  \\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}} $$\n",
    "\n",
    "The relationship between accuracy and precision can be understood in the following way:\n",
    "\n",
    "- Precision is a component of accuracy that specifically considers the positive predictions. If a model has high precision, it means that when it predicts a positive instance, it is likely to be correct. However, a model can have high accuracy even if its precision is not perfect.\n",
    "\n",
    "- If a model has high accuracy, it generally means that it is making correct predictions overall, both for positive and negative instances. However, a high accuracy does not guarantee a high precision.\n",
    "\n",
    "In summary, precision is a more focused metric when evaluating the accuracy of positive predictions, while accuracy provides an overall measure of correctness. A model can have high accuracy with varying levels of precision, depending on how well it performs on positive predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Give example where precision is significant compared to accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision becomes particularly significant in scenarios where the cost of false positives is high. Here's a common example:\n",
    "\n",
    "### Medical Diagnosis:\n",
    "Consider a medical test for a rare disease. Let's say the disease occurs in only 1 out of 1000 people (0.1%). If a model predicts a person has the disease, it may be more crucial to ensure that the prediction is correct because the consequences of a false positive (incorrectly diagnosing a healthy person as having the disease) can be severe.\n",
    "\n",
    "- **Scenario:**\n",
    "  - Total instances (population): 100,000\n",
    "  - Actual cases of the disease: 100 (0.1% of the population)\n",
    "  - Model predicts 200 cases, out of which 150 are correct (True Positives) and 50 are incorrect (False Positives).\n",
    "\n",
    "- **Metrics:**\n",
    "$$\n",
    " Accuracy = \\frac{150 + 99,850}{100,000} = 99.85 \n",
    "\n",
    "$$\n",
    "$$\n",
    "\n",
    "Precision = \\frac{150}{150 + 50} = 75\n",
    "$$\n",
    "In this example, the accuracy is high (99.85%), but the precision is 75%. The precision indicates that out of all the predicted positive cases, only 75% are true positives. This matters because falsely diagnosing a person with a rare disease can lead to unnecessary stress, treatments, and costs.\n",
    "\n",
    "In situations like medical diagnosis, fraud detection, or other contexts where the cost of false positives is high, precision becomes a more critical metric than accuracy. It helps to focus on the reliability of positive predictions, ensuring that when the model predicts a positive instance, it is more likely to be correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Give example where accuracy is significant compared to precision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy becomes significant in scenarios where the cost of both false positives and false negatives is relatively balanced, and the goal is to evaluate overall correctness. Here's an example:\n",
    "\n",
    "### Email Spam Detection:\n",
    "Consider a spam detection system for emails. In this scenario, false positives (classifying a legitimate email as spam) and false negatives (missing a spam email and classifying it as legitimate) both have consequences, but there may not be a strong preference for one over the other.\n",
    "\n",
    "- **Scenario:**\n",
    "  - Total emails: 10,000\n",
    "  - Legitimate emails: 8,000\n",
    "  - Spam emails: 2,000\n",
    "  - Model predicts 9,000 emails correctly (True Positives + True Negatives), and 1,000 incorrectly (False Positives + False Negatives).\n",
    "\n",
    "- **Metrics:**\n",
    "$$\n",
    "  Accuracy = \\frac{9,000}{10,000} = 90%\\)\n",
    "$$\n",
    "$$\n",
    "  Precision = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}}\n",
    "$$\n",
    "In this example, accuracy is significant because it provides an overall measure of how well the model is performing. Achieving a high accuracy of 90% indicates that the model is correctly classifying emails, both spam and legitimate, with a high rate of success.\n",
    "\n",
    "While precision is also important in spam detection to minimize false positives (classifying legitimate emails as spam), accuracy is valuable in situations where false positives and false negatives have comparable consequences. It helps to assess the model's correctness across both classes.\n",
    "\n",
    "In summary, accuracy is more significant when the goal is to evaluate the model's overall correctness, especially in situations where the costs associated with false positives and false negatives are balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;width:100%}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:16px;\n",
    "  overflow:hidden;padding:10px 10px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:16px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 10px;word-break:normal;}\n",
    ".tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top;}\n",
    ".col1 { width: 20%;}\n",
    ".col2 { width: 80%;}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky col1\">CONCLUSION</td>\n",
    "    <td class=\"tg-0pky\">\n",
    "\n",
    "In this experiment, I learned to create a Naive Bayes model for classifying specific text into particular classes.   \n",
    "    </td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bap-notebook",
   "language": "python",
   "name": "bap-notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
