{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tf  {border-collapse:collapse;border-spacing:0;width:99%}\n",
    ".tf td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tf th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tf .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}\n",
    ".col1 { width: 20%;}\n",
    ".col2 { width: 80%;}\n",
    "</style>\n",
    "<table class=\"tf\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-0pky col1\">Name:</th>\n",
    "    <th class=\"tg-0pky col2\">Pranay Singhvi</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky col1\">UID:</td>\n",
    "    <td class=\"tg-0pky col2\">2021300126</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style=\"text-align:center;font-weight:500;\">Experiment 7</p>\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;width:99%}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 10px;word-break:normal;}\n",
    ".tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top;}\n",
    ".col1 { width: 20%;}\n",
    ".col2 { width: 80%;}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-0pky col1\">Aim:</th>\n",
    "    <th class=\"tg-0pky col2\">Text Analysis: Exploring Chunking and Named Entity Recognition for Information Extraction from Text Corpora</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th class=\"tg-0pky col1\">Theory:</th>\n",
    "    <th class=\"tg-0pky col2\"> \n",
    "\n",
    "* **Chunking**\n",
    "\n",
    "   - **Purpose:** Groups words into meaningful phrases (chunks). It's a step above part-of-speech (POS) tagging but less complex than full parsing.\n",
    "   - **Types:**\n",
    "     - **Noun Phrase (NP):**  A phrase built around a noun (e.g., \"the big dog\")\n",
    "     - **Verb Phrase (VP):** A phrase built around a verb (e.g., \"is running quickly\")\n",
    "     - **Adjective Phrase (ADJP):**  A phrase built around an adjective (e.g., \"very happy\")\n",
    "     - **Adverb Phrase (ADVP):**  A phrase built around an adverb (e.g., \"quite slowly\")\n",
    "     - **Prepositional Phrase (PP):** A phrase starting with a preposition and including its object (e.g., \"on the table\")\n",
    "\n",
    "* **Named Entity Recognition (NER)**\n",
    "\n",
    "    - **Purpose:** Locates and classifies named entities in text into predefined categories.\n",
    "    - **Common NER Types:**\n",
    "        - **Persons (PER):** Names of people \n",
    "        - **Organizations (ORG):**  Companies, government bodies, etc.\n",
    "        - **Locations (LOC):**  Countries, cities, mountains, etc.\n",
    "        - **Dates and Times:** Specific dates, time expressions\n",
    "        - **Quantities:** Numerical values, measurements\n",
    "        - **Miscellaneous (MISC):** Other entities (products, events)\n",
    "\n",
    "**Methods**\n",
    "\n",
    "**1. Chunking**\n",
    "\n",
    "\n",
    "  **a) Regular Expressions**\n",
    "\n",
    "  - **Pros:** Flexible if you're familiar with regex.\n",
    "  - **Cons:** Regexes can get complex; they might not be as accurate as library-based methods.\n",
    "\n",
    "  **b) Libraries (like NLTK)**\n",
    "\n",
    "  \n",
    "  - **NLTK (Natural Language Toolkit):**\n",
    "         - Train a chunk parser for basic chunking.\n",
    "         - Use rule-based grammars for more customized patterns.\n",
    "     - **Pros:** Generally more accurate and robust than simple regex.\n",
    "     - **Cons:**  Can require some setup and understanding of NLP libraries.\n",
    "\n",
    "**2. Named Entity Recognition**\n",
    "\n",
    "   **a) Rule-Based with Regex** \n",
    "   - **Pros:** Simple if you need to target very specific entities.\n",
    "  - **Cons:** Limited; less adaptable to variations in entity forms.\n",
    "\n",
    "     **b) Libraries (like NLTK or spaCy)**\n",
    "\n",
    "      - **NLTK:** Offers a pre-trained NER model (`nltk.ne_chunk()`).\n",
    "      - **spaCy:** Popular library with efficient and highly customizable NER models.\n",
    "      - **Pros:** Powerful models, pre-trained on large datasets for better accuracy.\n",
    "      - **Cons:**  Might require more setup and resources.\n",
    "\n",
    "  </th>\n",
    "  </tr>\n",
    "</thead>\n",
    "</table> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Installation of NLTK and downloading the required corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Declare the sample text corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text corpus\n",
    "text_corpus = \"\"\"\n",
    "President Donald Trump visited France and met with French President Emmanuel Macron.\n",
    "The movie was directed by Steven Spielberg and starred Tom Hanks.\n",
    "The cat sat lazily on the mat.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Regular expression patterns for chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = r\"\"\"\n",
    "    NP: {<DT|JJ|NN.*>+}          # Chunk sequences of DT, JJ, NN\n",
    "    VP: {<VB.*><NP|PP|CLAUSE>+$}  # Chunk verbs and their arguments\n",
    "    ADJP: {<JJ.*><PP>?}           # Chunk adjectives with optional prepositional phrase\n",
    "    ADVP: {<RB.*>}                 # Chunk adverbs\n",
    "    PP: {<IN><NP>}                 # Chunk prepositions and their objects\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Chunking using regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_with_regex(text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "        tagged_words = nltk.pos_tag(words)\n",
    "        chunk_parser = nltk.RegexpParser(grammar)\n",
    "        chunks = chunk_parser.parse(tagged_words)\n",
    "        print(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Chunking using NLTK library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_with_library(text):\n",
    "    # Tokenize text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # Part-of-speech tagging\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    # Chunking using NLTK's built-in chunker\n",
    "    chunked = nltk.ne_chunk(tagged)\n",
    "    print(chunked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Named Entity Recognition using spaCy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_with_spacy_pretty_table(text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    table = PrettyTable([\"Entity\", \"Label\"])\n",
    "    for ent in doc.ents:\n",
    "        table.add_row([ent.text, ent.label_])\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking with regular expressions:\n",
      "(S\n",
      "  (NP President/NNP Donald/NNP Trump/NNP)\n",
      "  visited/VBD\n",
      "  (NP France/NNP)\n",
      "  and/CC\n",
      "  met/VBN\n",
      "  (PP with/IN (NP French/NNP President/NNP Emmanuel/NNP Macron/NNP))\n",
      "  ./.)\n",
      "(S\n",
      "  (NP The/DT movie/NN)\n",
      "  was/VBD\n",
      "  directed/VBN\n",
      "  (PP by/IN (NP Steven/NNP Spielberg/NNP))\n",
      "  and/CC\n",
      "  starred/VBD\n",
      "  (NP Tom/NNP Hanks/NNP)\n",
      "  ./.)\n",
      "(S\n",
      "  (NP The/DT cat/NN)\n",
      "  sat/VBD\n",
      "  (ADVP lazily/RB)\n",
      "  (PP on/IN (NP the/DT mat/NN))\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "# Chunking with regular expressions\n",
    "print(\"Chunking with regular expressions:\")\n",
    "chunk_with_regex(text_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chunking with NLTK library:\n",
      "(S\n",
      "  (NP President/NNP Donald/NNP Trump/NNP)\n",
      "  visited/VBD\n",
      "  (NP France/NNP)\n",
      "  and/CC\n",
      "  met/VBN\n",
      "  (PP with/IN (NP French/NNP President/NNP Emmanuel/NNP Macron/NNP))\n",
      "  ./.)\n",
      "(S\n",
      "  (NP The/DT movie/NN)\n",
      "  was/VBD\n",
      "  directed/VBN\n",
      "  (PP by/IN (NP Steven/NNP Spielberg/NNP))\n",
      "  and/CC\n",
      "  starred/VBD\n",
      "  (NP Tom/NNP Hanks/NNP)\n",
      "  ./.)\n",
      "(S\n",
      "  (NP The/DT cat/NN)\n",
      "  sat/VBD\n",
      "  (ADVP lazily/RB)\n",
      "  (PP on/IN (NP the/DT mat/NN))\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "# Chunking with NLTK library\n",
    "print(\"\\nChunking with NLTK library:\")\n",
    "chunk_with_nltk(text_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Named Entity Recognition with spaCy:\n",
      "+------------------+--------+\n",
      "|      Entity      | Label  |\n",
      "+------------------+--------+\n",
      "|   Donald Trump   | PERSON |\n",
      "|      France      |  GPE   |\n",
      "|      French      |  NORP  |\n",
      "| Emmanuel Macron  | PERSON |\n",
      "| Steven Spielberg | PERSON |\n",
      "|    Tom Hanks     | PERSON |\n",
      "+------------------+--------+\n"
     ]
    }
   ],
   "source": [
    "# Named Entity Recognition with spaCy library\n",
    "print(\"\\nNamed Entity Recognition with spaCy:\")\n",
    "ner_with_spacy_pretty_table(text_corpus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through this experiment, I discovered that combining regular expressions and libraries provides the most robust solution for extracting meaningful chunks and named entities from text. While regular expressions offer flexibility, libraries like NLTK and spaCy provide superior accuracy and efficiency for real-world natural language processing tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bap-notebook",
   "language": "python",
   "name": "bap-notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
